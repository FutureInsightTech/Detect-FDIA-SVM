{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0578c161",
   "metadata": {},
   "source": [
    "# Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b13302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bf7f3",
   "metadata": {},
   "source": [
    "## Getting the Features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6c47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sessionId', 'kwhTotal', 'dollars', 'created', 'ended', 'startTime',\n",
      "       'endTime', 'chargeTimeHrs', 'weekday', 'platform', 'distance', 'userId',\n",
      "       'stationId', 'locationId', 'managerVehicle', 'facilityType', 'Mon',\n",
      "       'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'reportedZip'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('station_data_dataverse.csv')\n",
    "\n",
    "# Print all of the features in the dataset\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e24ea57",
   "metadata": {},
   "source": [
    "# Adding New feature\n",
    "Adding a new feature calls false data injection\n",
    "## Code Explain:\n",
    "The code reads the CSV file named \"dataset.csv\" using the pandas library and stores it in a pandas DataFrame object called \"data\".\n",
    "\n",
    "Then, a new column named \"FalseDataInjection\" is added to the DataFrame using the assign() function from pandas. The values of this new column are generated randomly with numpy.random.randint() function, which generates integers randomly between 0 and 1 (inclusive). The size parameter specifies the number of rows in the DataFrame.\n",
    "\n",
    "Finally, the updated DataFrame with the new column is saved to a new CSV file named \"dataset_with_false_injection.csv\" using the to_csv() function from pandas. The index=False parameter ensures that the row index is not included in the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c260e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "df = pd.read_csv('station_data_dataverse.csv')\n",
    "\n",
    "# add FalseDataInjection column with random 0 or 1 values\n",
    "df['FalseDataInjection'] = np.random.randint(2, size=len(df))\n",
    "\n",
    "# save new dataset to CSV file\n",
    "df.to_csv('dataset_with_FDI.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66c7eb",
   "metadata": {},
   "source": [
    "## Checking for any null or empty value\n",
    "The above code reads the CSV file named \"dataset_with_FDI.csv\" using pandas library's read_csv function and stores it in a variable named \"df\".\n",
    "\n",
    "The next line uses the isnull() method of pandas dataframe to check for null values in each cell of the dataframe \"df\". It returns a boolean dataframe where True indicates a null value and False indicates a non-null value.\n",
    "\n",
    "Then, sum() method is used on this boolean dataframe which will return a new dataframe with the sum of all null values in each column of the original dataframe. This will give the count of null values in each column.\n",
    "\n",
    "Finally, the last line of code will print the count of null values in each column of the dataframe.\n",
    "\n",
    "## Output Explain:\n",
    "This output shows the number of null or missing values in each column of the dataset. For example, the 'distance' column has 1065 missing values while other columns such as 'sessionId', 'kwhTotal', 'dollars', 'created', etc have no missing values. The 'FalseDataInjection' column also has no missing values as expected since we added random values of either 0 or 1 for this feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b24497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessionId                0\n",
      "kwhTotal                 0\n",
      "dollars                  0\n",
      "created                  0\n",
      "ended                    0\n",
      "startTime                0\n",
      "endTime                  0\n",
      "chargeTimeHrs            0\n",
      "weekday                  0\n",
      "platform                 0\n",
      "distance              1065\n",
      "userId                   0\n",
      "stationId                0\n",
      "locationId               0\n",
      "managerVehicle           0\n",
      "facilityType             0\n",
      "Mon                      0\n",
      "Tues                     0\n",
      "Wed                      0\n",
      "Thurs                    0\n",
      "Fri                      0\n",
      "Sat                      0\n",
      "Sun                      0\n",
      "reportedZip              0\n",
      "FalseDataInjection       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any null or missing values in the DataFrame\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ac5a8",
   "metadata": {},
   "source": [
    "# Removing any null or empty cell from the data set:\n",
    "The code uses the dropna function from pandas to remove any rows containing null or missing values from the dataset. The argument inplace=True specifies that the changes should be made to the original dataset.\n",
    "\n",
    "This code will remove any rows with missing or null values from the dataset, allowing for cleaner and more accurate data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with null or empty values\n",
    "df = df.dropna()\n",
    "\n",
    "# Save the cleaned dataset to a new csv file\n",
    "df.to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d586fc",
   "metadata": {},
   "source": [
    "# Converting Text Data into numberical representation using One-hot conversion\n",
    "\n",
    "## Code explanation:\n",
    "In this code, we first load the dataset into a pandas DataFrame object using the read_csv() function. Then, we use the get_dummies() function to perform one-hot encoding on the Weekday feature, which creates a new DataFrame with binary features for each weekday. We add these new features to the original DataFrame using the concat() function, and then we drop the original Weekday feature using the drop() function. Finally, we print the updated DataFrame using the head() function.\n",
    "\n",
    "After performing one-hot encoding, you can use the other features in the SVM model to detect false data injection attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the 'Weekday' feature\n",
    "one_hot = pd.get_dummies(df['weekday'], prefix='weekday')\n",
    "\n",
    "# Add the new one-hot encoded features to the original dataset\n",
    "df = pd.concat([df, one_hot], axis=1)\n",
    "\n",
    "# Drop the original 'Weekday' feature since it's no longer needed\n",
    "df.drop('weekday', axis=1, inplace=True)\n",
    "\n",
    "# Print the updated dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f12748",
   "metadata": {},
   "source": [
    "# Apply SVM Model\n",
    "\n",
    "## What if we change the kernel of SVM will the performace of the model change\n",
    "Yes, changing the kernel of SVM can impact the performance of the model. The choice of kernel depends on the nature of the data and the problem you are trying to solve.\n",
    "\n",
    "In the code snippet provided earlier, the kernel used is 'rbf' which stands for radial basis function. This is a commonly used kernel that can work well with non-linearly separable data. However, other kernels such as linear, polynomial, and sigmoid can also be used depending on the problem at hand.\n",
    "\n",
    "It's generally a good idea to experiment with different kernels and compare their performance using metrics such as accuracy, precision, recall, and F1-score. This can help you choose the best kernel for your particular problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0760e2",
   "metadata": {},
   "source": [
    "## SVM Model with RBF Kernel & Box plot\n",
    "## Code Explain:\n",
    "The above code is implementing an SVM (Support Vector Machine) classifier using the Scikit-learn library in Python to predict the 'managerVehicle' target feature of the dataset based on the selected features.\n",
    "\n",
    "Here's a breakdown of the code:\n",
    "\n",
    "1. First, the necessary libraries are imported, including pandas for data manipulation, svm for implementing the SVM classifier, and cross_val_score for cross-validation of the model.\n",
    "\n",
    "2. Then, the selected features for SVM are defined in a list called 'features'.\n",
    "\n",
    "3. The dataset is split into two parts - the features (X) and the target (y). X contains all the features except the 'managerVehicle' target feature, and y contains only the 'managerVehicle' target feature.\n",
    "\n",
    "4. An SVM classifier with the RBF kernel is created.\n",
    "\n",
    "5. The performance of the model is evaluated using 5-fold cross-validation, and the mean accuracy and standard deviation of the cross-validation scores are printed.\n",
    "\n",
    "**Note:** The dataset used in this code is assumed to be named 'df' after the cleaning process. However, the code is commented out for reading the cleaned dataset from a CSV file named 'cleaned_dataset.csv'.\n",
    "\n",
    "## Output Explain:\n",
    "The output means that the mean accuracy of the SVM classifier with RBF kernel is 0.64, with a standard deviation of 0.18. The cross-validation is performed using 5 folds, so the accuracy score is the average of the 5 scores obtained during the cross-validation process.\n",
    "\n",
    "The standard deviation provides information about the variability of the accuracy scores obtained from the different folds. A higher standard deviation means that the accuracy scores are more spread out and less reliable, while a lower standard deviation indicates more consistent and reliable results.\n",
    "\n",
    "In summary, the SVM classifier with RBF kernel has an average accuracy of 0.64, which means that it correctly predicts the value of the \"managerVehicle\" target variable in 64% of the cases, on average. However, the relatively high standard deviation of 0.18 suggests that the performance of the classifier may be variable and less reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for SVM\n",
    "features = ['kwhTotal', 'dollars', 'chargeTimeHrs', 'distance', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'FalseDataInjection']\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df['managerVehicle']\n",
    "\n",
    "# Create SVM classifier with RBF kernel\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Evaluate performance using 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the mean accuracy and standard deviation of the cross-validation scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "plt.boxplot(scores)\n",
    "plt.title('Cross-validation scores')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6d21f",
   "metadata": {},
   "source": [
    "## SVM  With Confusion Matrix & With RBF Kernel:\n",
    "This code is an extension of the previous code that trains an SVM classifier on the dataset and evaluates its performance using cross-validation. It adds a confusion matrix visualization to further analyze the classifier's performance.\n",
    "\n",
    "After selecting the features for SVM and splitting the data into features (X) and target (y), a SVM classifier with an RBF kernel is created. Then, 5-fold cross-validation is used to evaluate the classifier's performance, and the mean accuracy and standard deviation of the cross-validation scores are printed.\n",
    "\n",
    "Next, the SVM classifier is trained on the entire dataset, and its predictions on the target variable (y_pred) are obtained. Finally, the confusion matrix is calculated using the true labels (y) and predicted labels (y_pred), and a heatmap visualization of the matrix is plotted using the seaborn library.\n",
    "\n",
    "The confusion matrix helps to visualize the performance of the classifier by showing the number of true positives, true negatives, false positives, and false negatives. The heatmap visualization makes it easier to interpret the matrix by highlighting the values using different colors.\n",
    "\n",
    "## Output Explain:\n",
    "The output means that the mean accuracy of the SVM classifier with RBF kernel is 0.64, with a standard deviation of 0.18. The cross-validation is performed using 5 folds, so the accuracy score is the average of the 5 scores obtained during the cross-validation process.\n",
    "\n",
    "The standard deviation provides information about the variability of the accuracy scores obtained from the different folds. A higher standard deviation means that the accuracy scores are more spread out and less reliable, while a lower standard deviation indicates more consistent and reliable results.\n",
    "\n",
    "In summary, the SVM classifier with RBF kernel has an average accuracy of 0.64, which means that it correctly predicts the value of the \"managerVehicle\" target variable in 64% of the cases, on average. However, the relatively high standard deviation of 0.18 suggests that the performance of the classifier may be variable and less reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77923aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for SVM\n",
    "features = ['kwhTotal', 'dollars', 'chargeTimeHrs', 'distance', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'FalseDataInjection']\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df['managerVehicle']\n",
    "\n",
    "# Create SVM classifier with RBF kernel\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Evaluate performance using 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the mean accuracy and standard deviation of the cross-validation scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Train and test the SVM classifier on the data\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3433df",
   "metadata": {},
   "source": [
    "## SVM With Confusion Matrix & with Linear  Kernel:\n",
    "This code is using SVM (Support Vector Machines) to classify electric vehicle charging sessions based on the features in the input dataset.\n",
    "\n",
    "First, the necessary libraries (pandas, svm, cross_val_score, confusion_matrix, and seaborn) are imported.\n",
    "\n",
    "The features used in the SVM model are defined and extracted from the cleaned dataset.\n",
    "\n",
    "The data is split into two parts: X, which contains the features used for classification, and y, which contains the target variable (in this case, the binary label 'managerVehicle').\n",
    "\n",
    "An SVM classifier is created using a linear kernel, and its performance is evaluated using 5-fold cross-validation. The accuracy and standard deviation of the cross-validation scores are printed to the console.\n",
    "\n",
    "The SVM classifier is trained and tested on the data, and its predictions are stored in a variable y_pred.\n",
    "\n",
    "Finally, a confusion matrix is generated using the true labels and the predicted labels, and it is visualized using a heatmap from the seaborn library.\n",
    "\n",
    "By changing the kernel of the SVM model to linear, the accuracy of the model decreased to 0.58 (+/- 0.15) compared to 0.64 (+/- 0.18) with an RBF kernel.\n",
    "## Output Explain:\n",
    "The output \"Accuracy: 0.58 (+/- 0.15)\" means that the average accuracy of the SVM model using a linear kernel is 0.58, and the standard deviation of the accuracy across different cross-validation folds is 0.15.\n",
    "\n",
    "In other words, the model is correctly predicting the target variable (managerVehicle) approximately 58% of the time on average. However, there is some variability in the accuracy across different folds, with a standard deviation of 0.15, which suggests that the performance of the model may not be very consistent.\n",
    "\n",
    "It's worth noting that the accuracy of the model depends on many factors, including the quality of the data, the choice of features, and the choice of hyperparameters (such as the kernel type). Therefore, it's important to evaluate the model using different kernels and hyperparameters to choose the best model for the given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaed129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for SVM\n",
    "features = ['kwhTotal', 'dollars', 'chargeTimeHrs', 'distance', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'managerVehicle']\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df['FalseDataInjection']\n",
    "\n",
    "# Create SVM classifier with linear kernel\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Evaluate performance using 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the mean accuracy and standard deviation of the cross-validation scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Train and test the SVM classifier on the data\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "# Calculate the precision score\n",
    "precision = precision_score(y, y_pred)\n",
    "\n",
    "# Print the precision score\n",
    "print(\"Precision: %0.2f\" % precision)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61016769",
   "metadata": {},
   "source": [
    "## SVM with Linear Kernel & checking the Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for SVM\n",
    "features = ['kwhTotal', 'dollars', 'chargeTimeHrs', 'distance', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'managerVehicle']\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df['FalseDataInjection']\n",
    "\n",
    "# Create SVM classifier with linear kernel\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Evaluate performance using 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the mean accuracy and standard deviation of the cross-validation scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Train and test the SVM classifier on the data\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "# Calculate the precision score\n",
    "precision = precision_score(y, y_pred)\n",
    "\n",
    "# Print the precision score\n",
    "print(\"Precision: %0.2f\" % precision)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e937b",
   "metadata": {},
   "source": [
    "## SVM With Confussion Matrix & With Polynomial Kernel:\n",
    "\n",
    "\n",
    "## Output Explain:\n",
    "In the context of the code provided, \"Accuracy: 0.58 (+/- 0.11)\" is the output of the cross-validation score evaluation performed on the SVM model with a polynomial kernel.\n",
    "\n",
    "The first value, 0.58, represents the mean accuracy score of the model across all the folds of the cross-validation. This means that, on average, the model correctly predicted the vehicle manager for 58% of the data points.\n",
    "\n",
    "The second value, +/- 0.11, represents the range of the accuracy scores across all the folds of the cross-validation. It is a measure of the variability of the model's performance. The range is expressed as twice the standard deviation of the accuracy scores. So, in this case, the range is from 0.47 to 0.69 (0.58 plus or minus 0.11).\n",
    "\n",
    "Therefore, the output indicates that the model's performance is not very consistent, and the accuracy of the model may vary significantly depending on the data points used for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for SVM\n",
    "features = ['kwhTotal', 'dollars', 'chargeTimeHrs', 'distance', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun', 'FalseDataInjection']\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df['managerVehicle']\n",
    "\n",
    "# Create SVM classifier with polynomial kernel\n",
    "clf = svm.SVC(kernel='poly')\n",
    "\n",
    "# Evaluate performance using 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the mean accuracy and standard deviation of the cross-validation scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Train and test the SVM classifier on the data\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6849a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cf57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfd939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0619f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2893146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b4ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036af8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229e967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
